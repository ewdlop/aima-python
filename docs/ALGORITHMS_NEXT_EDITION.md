# ğŸš€ Index of Algorithms for AIMA n-th Edition (Future)

## é è¨ˆæ–°å¢çš„ç¾ä»£ AI ç®—æ³•èˆ‡åœ–è¡¨

æœ¬æ–‡æª”åˆ—å‡ºæœªä¾†ç‰ˆæœ¬å¯èƒ½æ–°å¢çš„ç®—æ³•ï¼Œåæ˜  2020 å¹´ä»£çš„ AI ç ”ç©¶é€²å±•ã€‚

---

## ğŸ“Š æ–°å¢ç®—æ³•çµ±è¨ˆ

- **æ–°å¢ç« ç¯€**: 3 å€‹ï¼ˆæ·±åº¦å­¸ç¿’é€²éšã€å¤§å‹èªè¨€æ¨¡å‹ã€ç”Ÿæˆå¼ AIï¼‰
- **æ–°å¢ç®—æ³•**: 50+ å€‹
- **æ–°å¢åœ–è¡¨**: 60+ å€‹
- **æ›´æ–°ç« ç¯€**: æ‰€æœ‰ä¸»è¦ç« ç¯€

---

## ğŸ†• Part VII: Deep Neural Networks (æ·±åº¦ç¥ç¶“ç¶²çµ¡é€²éš)

### Chapter 26: Advanced Neural Network Architectures (é€²éšç¥ç¶“ç¶²çµ¡æ¶æ§‹)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 26.1 | Convolutional-Neural-Network | `CNN` | [`deep_learning.py`][dl] | LeCun | 1998 |
| 26.2 | Conv-Layer-Forward-Pass | `conv_forward` | [`deep_learning.py`][dl] | - | - |
| 26.3 | Max-Pooling | `max_pooling` | [`deep_learning.py`][dl] | - | - |
| 26.4 | Batch-Normalization | `batch_norm` | [`deep_learning.py`][dl] | Ioffe & Szegedy | 2015 |
| 26.5 | Dropout-Regularization | `dropout` | [`deep_learning.py`][dl] | Hinton et al. | 2012 |
| 26.6 | ResNet-Block | `residual_block` | [`deep_learning.py`][dl] | He et al. | 2015 |
| 26.7 | Skip-Connection | `skip_connection` | [`deep_learning.py`][dl] | - | - |
| 26.8 | DenseNet-Block | `dense_block` | [`deep_learning.py`][dl] | Huang et al. | 2017 |
| 26.9 | Inception-Module | `inception_module` | [`deep_learning.py`][dl] | Szegedy et al. | 2015 |
| 26.10 | MobileNet-Block | `mobilenet_block` | [`deep_learning.py`][dl] | Howard et al. | 2017 |

---

### Chapter 27: Attention Mechanisms and Transformers (æ³¨æ„åŠ›æ©Ÿåˆ¶èˆ‡ Transformer)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 27.1 | Recurrent-Neural-Network | `RNN` | [`sequence_models.py`][seq] | Rumelhart | 1986 |
| 27.2 | LSTM-Cell | `LSTM` | [`sequence_models.py`][seq] | Hochreiter & Schmidhuber | 1997 |
| 27.3 | GRU-Cell | `GRU` | [`sequence_models.py`][seq] | Cho et al. | 2014 |
| 27.4 | Seq2Seq-Model | `seq2seq` | [`sequence_models.py`][seq] | Sutskever et al. | 2014 |
| 27.5 | Attention-Mechanism | `attention` | [`attention.py`][attn] | Bahdanau et al. | 2015 |
| 27.6 | **Scaled-Dot-Product-Attention** ğŸŒŸ | `scaled_dot_product_attention` | [`attention.py`][attn] | Vaswani et al. | 2017 |
| 27.7 | **Multi-Head-Attention** ğŸŒŸ | `multi_head_attention` | [`attention.py`][attn] | Vaswani et al. | 2017 |
| 27.8 | **Transformer-Encoder** ğŸŒŸ | `transformer_encoder` | [`transformers.py`][trans] | Vaswani et al. | 2017 |
| 27.9 | **Transformer-Decoder** ğŸŒŸ | `transformer_decoder` | [`transformers.py`][trans] | Vaswani et al. | 2017 |
| 27.10 | Positional-Encoding | `positional_encoding` | [`transformers.py`][trans] | - | - |
| 27.11 | Self-Attention | `self_attention` | [`attention.py`][attn] | - | - |
| 27.12 | Cross-Attention | `cross_attention` | [`attention.py`][attn] | - | - |

---

### Chapter 28: Large Language Models (å¤§å‹èªè¨€æ¨¡å‹)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 28.1 | **BERT-Pretraining** ğŸŒŸ | `bert_pretrain` | [`language_models.py`][lm] | Devlin et al. | 2018 |
| 28.2 | Masked-Language-Modeling | `masked_lm` | [`language_models.py`][lm] | - | - |
| 28.3 | Next-Sentence-Prediction | `next_sentence_pred` | [`language_models.py`][lm] | - | - |
| 28.4 | **GPT-Architecture** ğŸŒŸ | `gpt_model` | [`language_models.py`][lm] | Radford et al. | 2018 |
| 28.5 | Causal-Language-Modeling | `causal_lm` | [`language_models.py`][lm] | - | - |
| 28.6 | **Fine-Tuning-LLM** | `fine_tune` | [`language_models.py`][lm] | - | - |
| 28.7 | **Prompt-Engineering** | `prompt_template` | [`language_models.py`][lm] | - | 2021 |
| 28.8 | **Few-Shot-Learning** ğŸŒŸ | `few_shot_learning` | [`language_models.py`][lm] | Brown et al. | 2020 |
| 28.9 | **In-Context-Learning** | `in_context_learning` | [`language_models.py`][lm] | - | 2020 |
| 28.10 | **Chain-of-Thought-Prompting** | `chain_of_thought` | [`language_models.py`][lm] | Wei et al. | 2022 |
| 28.11 | **RLHF** (Reinforcement Learning from Human Feedback) ğŸŒŸ | `rlhf` | [`language_models.py`][lm] | Christiano et al. | 2017 |
| 28.12 | Instruction-Tuning | `instruction_tuning` | [`language_models.py`][lm] | - | 2022 |
| 28.13 | **Retrieval-Augmented-Generation** | `rag` | [`language_models.py`][lm] | Lewis et al. | 2020 |

---

## ğŸ¨ Part VIII: Generative AI (ç”Ÿæˆå¼ AI)

### Chapter 29: Generative Models (ç”Ÿæˆæ¨¡å‹)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 29.1 | Autoencoder | `autoencoder` | [`generative.py`][gen] | - | 1980s |
| 29.2 | Variational-Autoencoder | `VAE` | [`generative.py`][gen] | Kingma & Welling | 2013 |
| 29.3 | VAE-Reparameterization-Trick | `reparameterization` | [`generative.py`][gen] | - | - |
| 29.4 | **GAN-Architecture** ğŸŒŸ | `GAN` | [`generative.py`][gen] | Goodfellow et al. | 2014 |
| 29.5 | GAN-Training-Loop | `gan_train` | [`generative.py`][gen] | - | - |
| 29.6 | DCGAN (Deep Convolutional GAN) | `DCGAN` | [`generative.py`][gen] | Radford et al. | 2015 |
| 29.7 | **StyleGAN** | `StyleGAN` | [`generative.py`][gen] | Karras et al. | 2019 |
| 29.8 | Conditional-GAN | `CGAN` | [`generative.py`][gen] | Mirza & Osindero | 2014 |
| 29.9 | CycleGAN | `CycleGAN` | [`generative.py`][gen] | Zhu et al. | 2017 |
| 29.10 | **Diffusion-Model** ğŸŒŸ | `diffusion_model` | [`diffusion.py`][diff] | Sohl-Dickstein et al. | 2015 |
| 29.11 | **DDPM** (Denoising Diffusion Probabilistic Models) ğŸŒŸ | `DDPM` | [`diffusion.py`][diff] | Ho et al. | 2020 |
| 29.12 | Diffusion-Forward-Process | `diffusion_forward` | [`diffusion.py`][diff] | - | - |
| 29.13 | Diffusion-Reverse-Process | `diffusion_reverse` | [`diffusion.py`][diff] | - | - |
| 29.14 | **Stable-Diffusion** ğŸŒŸ | `stable_diffusion` | [`diffusion.py`][diff] | Rombach et al. | 2022 |
| 29.15 | Latent-Diffusion | `latent_diffusion` | [`diffusion.py`][diff] | - | - |
| 29.16 | **CLIP** (Contrastive Language-Image Pre-training) | `CLIP` | [`multimodal.py`][mm] | Radford et al. | 2021 |

---

### Chapter 30: Multimodal AI (å¤šæ¨¡æ…‹ AI)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 30.1 | Vision-Transformer | `ViT` | [`vision_models.py`][vis] | Dosovitskiy et al. | 2020 |
| 30.2 | Patch-Embedding | `patch_embed` | [`vision_models.py`][vis] | - | - |
| 30.3 | **DALL-E-Architecture** ğŸŒŸ | `dalle` | [`multimodal.py`][mm] | Ramesh et al. | 2021 |
| 30.4 | Image-GPT | `image_gpt` | [`multimodal.py`][mm] | Chen et al. | 2020 |
| 30.5 | **Flamingo** | `flamingo` | [`multimodal.py`][mm] | Alayrac et al. | 2022 |
| 30.6 | Text-to-Image-Generation | `text_to_image` | [`multimodal.py`][mm] | - | - |
| 30.7 | Image-Captioning | `image_caption` | [`multimodal.py`][mm] | - | - |
| 30.8 | Visual-Question-Answering | `vqa` | [`multimodal.py`][mm] | - | - |

---

## ğŸ® Part V (Expanded): Advanced Reinforcement Learning

### Chapter 21 (Extended): Modern RL Algorithms

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 21.9 | **Deep-Q-Network (DQN)** ğŸŒŸ | `DQN` | [`deep_rl.py`][drl] | Mnih et al. | 2015 |
| 21.10 | Experience-Replay | `experience_replay` | [`deep_rl.py`][drl] | - | - |
| 21.11 | Target-Network | `target_network` | [`deep_rl.py`][drl] | - | - |
| 21.12 | Double-DQN | `double_dqn` | [`deep_rl.py`][drl] | van Hasselt et al. | 2015 |
| 21.13 | Dueling-DQN | `dueling_dqn` | [`deep_rl.py`][drl] | Wang et al. | 2016 |
| 21.14 | Prioritized-Experience-Replay | `prioritized_replay` | [`deep_rl.py`][drl] | Schaul et al. | 2015 |
| 21.15 | **Policy-Gradient** ğŸŒŸ | `policy_gradient` | [`deep_rl.py`][drl] | Sutton et al. | 2000 |
| 21.16 | REINFORCE-Algorithm | `reinforce` | [`deep_rl.py`][drl] | Williams | 1992 |
| 21.17 | **Actor-Critic** | `actor_critic` | [`deep_rl.py`][drl] | Konda & Tsitsiklis | 2000 |
| 21.18 | **A3C** (Asynchronous Actor-Critic) | `A3C` | [`deep_rl.py`][drl] | Mnih et al. | 2016 |
| 21.19 | **PPO** (Proximal Policy Optimization) ğŸŒŸ | `PPO` | [`deep_rl.py`][drl] | Schulman et al. | 2017 |
| 21.20 | Trust-Region-Policy-Optimization | `TRPO` | [`deep_rl.py`][drl] | Schulman et al. | 2015 |
| 21.21 | Soft-Actor-Critic | `SAC` | [`deep_rl.py`][drl] | Haarnoja et al. | 2018 |
| 21.22 | **AlphaZero-MCTS** ğŸŒŸ | `alphazero_mcts` | [`games_rl.py`][grl] | Silver et al. | 2017 |
| 21.23 | Monte-Carlo-Tree-Search-Neural | `mcts_neural` | [`games_rl.py`][grl] | - | - |
| 21.24 | Model-Based-RL | `model_based_rl` | [`deep_rl.py`][drl] | - | - |
| 21.25 | World-Models | `world_models` | [`deep_rl.py`][drl] | Ha & Schmidhuber | 2018 |

---

## ğŸ”¬ Part IX: Modern AI Techniques (ç¾ä»£ AI æŠ€è¡“)

### Chapter 31: Self-Supervised Learning (è‡ªç›£ç£å­¸ç¿’)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 31.1 | Contrastive-Learning | `contrastive_learning` | [`ssl.py`][ssl] | - | - |
| 31.2 | **SimCLR** | `simclr` | [`ssl.py`][ssl] | Chen et al. | 2020 |
| 31.3 | **MoCo** (Momentum Contrast) | `moco` | [`ssl.py`][ssl] | He et al. | 2020 |
| 31.4 | **BYOL** (Bootstrap Your Own Latent) | `byol` | [`ssl.py`][ssl] | Grill et al. | 2020 |
| 31.5 | Data-Augmentation-Pipeline | `augmentation` | [`ssl.py`][ssl] | - | - |
| 31.6 | Pretext-Task | `pretext_task` | [`ssl.py`][ssl] | - | - |

---

### Chapter 32: Meta-Learning and Few-Shot Learning (å…ƒå­¸ç¿’èˆ‡å°æ¨£æœ¬å­¸ç¿’)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 32.1 | **MAML** (Model-Agnostic Meta-Learning) ğŸŒŸ | `MAML` | [`meta_learning.py`][meta] | Finn et al. | 2017 |
| 32.2 | Meta-Gradient-Update | `meta_gradient` | [`meta_learning.py`][meta] | - | - |
| 32.3 | Prototypical-Networks | `prototypical_net` | [`meta_learning.py`][meta] | Snell et al. | 2017 |
| 32.4 | Matching-Networks | `matching_net` | [`meta_learning.py`][meta] | Vinyals et al. | 2016 |
| 32.5 | Siamese-Networks | `siamese_net` | [`meta_learning.py`][meta] | Koch et al. | 2015 |
| 32.6 | Relation-Networks | `relation_net` | [`meta_learning.py`][meta] | Sung et al. | 2018 |

---

### Chapter 33: Neural Architecture Search (ç¥ç¶“æ¶æ§‹æœç´¢)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 33.1 | NAS-Search-Space | `nas_search_space` | [`nas.py`][nas] | - | - |
| 33.2 | **ENAS** (Efficient NAS) | `ENAS` | [`nas.py`][nas] | Pham et al. | 2018 |
| 33.3 | **DARTS** (Differentiable Architecture Search) | `DARTS` | [`nas.py`][nas] | Liu et al. | 2018 |
| 33.4 | NASNet-Cell | `nasnet_cell` | [`nas.py`][nas] | Zoph et al. | 2018 |
| 33.5 | AutoML-Pipeline | `automl` | [`nas.py`][nas] | - | - |

---

### Chapter 34: Explainable AI (å¯è§£é‡‹ AI)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 34.1 | **LIME** (Local Interpretable Model-Agnostic Explanations) ğŸŒŸ | `LIME` | [`explainable_ai.py`][xai] | Ribeiro et al. | 2016 |
| 34.2 | **SHAP** (SHapley Additive exPlanations) ğŸŒŸ | `SHAP` | [`explainable_ai.py`][xai] | Lundberg & Lee | 2017 |
| 34.3 | Grad-CAM | `grad_cam` | [`explainable_ai.py`][xai] | Selvaraju et al. | 2017 |
| 34.4 | Integrated-Gradients | `integrated_gradients` | [`explainable_ai.py`][xai] | Sundararajan et al. | 2017 |
| 34.5 | Attention-Visualization | `attention_viz` | [`explainable_ai.py`][xai] | - | - |
| 34.6 | Feature-Attribution | `feature_attribution` | [`explainable_ai.py`][xai] | - | - |

---

### Chapter 35: Federated Learning and Privacy (è¯é‚¦å­¸ç¿’èˆ‡éš±ç§)

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 35.1 | **Federated-Averaging** ğŸŒŸ | `federated_averaging` | [`federated.py`][fed] | McMahan et al. | 2017 |
| 35.2 | Differential-Privacy | `differential_privacy` | [`privacy.py`][priv] | Dwork et al. | 2006 |
| 35.3 | Private-Aggregation | `private_aggregation` | [`privacy.py`][priv] | - | - |
| 35.4 | Secure-Multi-Party-Computation | `smpc` | [`privacy.py`][priv] | - | - |
| 35.5 | Homomorphic-Encryption | `homomorphic_enc` | [`privacy.py`][priv] | - | - |

---

## ğŸ”„ æ›´æ–°ç¾æœ‰ç« ç¯€çš„æ–°ç®—æ³•

### Chapter 18 (Extended): Modern Deep Learning

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 18.35 | **Adam-Optimizer** ğŸŒŸ | `Adam` | [`optimizers.py`][opt] | Kingma & Ba | 2014 |
| 18.36 | RMSprop-Optimizer | `RMSprop` | [`optimizers.py`][opt] | Hinton | 2012 |
| 18.37 | Learning-Rate-Scheduling | `lr_schedule` | [`optimizers.py`][opt] | - | - |
| 18.38 | Weight-Initialization-Xavier | `xavier_init` | [`utils.py`][utils] | Glorot & Bengio | 2010 |
| 18.39 | Weight-Initialization-He | `he_init` | [`utils.py`][utils] | He et al. | 2015 |
| 18.40 | Gradient-Clipping | `gradient_clipping` | [`utils.py`][utils] | - | - |

---

### Chapter 22-23 (Extended): Modern NLP

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 23.6 | **Word2Vec** ğŸŒŸ | `word2vec` | [`embeddings.py`][emb] | Mikolov et al. | 2013 |
| 23.7 | Skip-Gram-Model | `skip_gram` | [`embeddings.py`][emb] | - | - |
| 23.8 | CBOW (Continuous Bag of Words) | `cbow` | [`embeddings.py`][emb] | - | - |
| 23.9 | **GloVe** | `glove` | [`embeddings.py`][emb] | Pennington et al. | 2014 |
| 23.10 | **FastText** | `fasttext` | [`embeddings.py`][emb] | Bojanowski et al. | 2017 |
| 23.11 | **ELMo** | `elmo` | [`embeddings.py`][emb] | Peters et al. | 2018 |
| 23.12 | Contextualized-Embeddings | `contextualized_emb` | [`embeddings.py`][emb] | - | - |
| 23.13 | **Tokenization-BPE** | `bpe_tokenizer` | [`tokenizers.py`][tok] | Sennrich et al. | 2016 |
| 23.14 | WordPiece-Tokenization | `wordpiece` | [`tokenizers.py`][tok] | - | - |
| 23.15 | SentencePiece | `sentencepiece` | [`tokenizers.py`][tok] | Kudo & Richardson | 2018 |

---

### Chapter 24 (Extended): Modern Computer Vision

| **Figure** | **Name** | **Name (in repository)** | **File** | **Pioneer** | **Year** |
|:-----------|:---------|:-------------------------|:---------|:------------|:---------|
| 24.9 | **YOLO** (You Only Look Once) ğŸŒŸ | `YOLO` | [`object_detection.py`][od] | Redmon et al. | 2016 |
| 24.10 | **R-CNN** | `RCNN` | [`object_detection.py`][od] | Girshick et al. | 2014 |
| 24.11 | Fast-R-CNN | `fast_rcnn` | [`object_detection.py`][od] | Girshick | 2015 |
| 24.12 | Faster-R-CNN | `faster_rcnn` | [`object_detection.py`][od] | Ren et al. | 2015 |
| 24.13 | **Mask-R-CNN** | `mask_rcnn` | [`segmentation.py`][seg] | He et al. | 2017 |
| 24.14 | Semantic-Segmentation | `semantic_seg` | [`segmentation.py`][seg] | - | - |
| 24.15 | Instance-Segmentation | `instance_seg` | [`segmentation.py`][seg] | - | - |
| 24.16 | **U-Net** | `unet` | [`segmentation.py`][seg] | Ronneberger et al. | 2015 |
| 24.17 | DeepLab | `deeplab` | [`segmentation.py`][seg] | Chen et al. | 2017 |

---

## ğŸ“Š æ–°å¢è³‡æ–™çµæ§‹

### Extended Data Structures

| **Figure** | **Name (in repository)** | **File** | **Description** |
|:-----------|:-------------------------|:---------|:----------------|
| 26.N | ImageNet-Dataset | [`datasets.py`][data] | å¤§è¦æ¨¡åœ–åƒåˆ†é¡æ•¸æ“šé›† |
| 27.N | COCO-Dataset | [`datasets.py`][data] | ç›®æ¨™æª¢æ¸¬å’Œåˆ†å‰²æ•¸æ“šé›† |
| 28.N | SQuAD-Dataset | [`datasets.py`][data] | å•ç­”æ•¸æ“šé›† |
| 28.N | GLUE-Benchmark | [`datasets.py`][data] | NLP åŸºæº–æ¸¬è©¦é›† |
| 29.N | CelebA-Dataset | [`datasets.py`][data] | äººè‡‰å±¬æ€§æ•¸æ“šé›† |
| 30.N | Attention-Pattern-Visualizer | [`visualizers.py`][viz] | æ³¨æ„åŠ›æ¨¡å¼å¯è¦–åŒ–å·¥å…· |

---

## ğŸŒŸ é‡é»æ–°ç®—æ³•ï¼ˆå¿…é ˆå¯¦ç¾ï¼‰

### æ ¸å¿ƒç®—æ³•æ¨™è¨˜ç‚º ğŸŒŸ

1. **Transformer ç›¸é—œ**
   - Scaled Dot-Product Attention (Figure 27.6)
   - Multi-Head Attention (Figure 27.7)
   - Transformer Encoder/Decoder (Figure 27.8-9)

2. **å¤§å‹èªè¨€æ¨¡å‹**
   - BERT (Figure 28.1)
   - GPT (Figure 28.4)
   - Few-Shot Learning (Figure 28.8)
   - RLHF (Figure 28.11)

3. **ç”Ÿæˆå¼ AI**
   - GAN (Figure 29.4)
   - Diffusion Models (Figure 29.10)
   - DDPM (Figure 29.11)
   - Stable Diffusion (Figure 29.14)

4. **å¼·åŒ–å­¸ç¿’**
   - DQN (Figure 21.9)
   - PPO (Figure 21.19)
   - AlphaZero MCTS (Figure 21.22)

5. **è¨ˆç®—æ©Ÿè¦–è¦º**
   - YOLO (Figure 24.9)
   - Mask R-CNN (Figure 24.13)

6. **å¯è§£é‡‹ AI**
   - LIME (Figure 34.1)
   - SHAP (Figure 34.2)

---

## ğŸ‘¥ æ–°ç®—æ³•çš„å…ˆé©…è€…ç¸½è¦½

### Transformer æ™‚ä»£ï¼ˆ2017-ï¼‰

- **Ashish Vaswani et al.** - Transformer ("Attention Is All You Need", 2017)
- **Jacob Devlin et al.** - BERT (2018)
- **Alec Radford et al.** - GPT series (2018-2023)
- **Tom Brown et al.** - GPT-3, Few-Shot Learning (2020)

### ç”Ÿæˆå¼ AI

- **Ian Goodfellow** - GAN (2014)
- **Jascha Sohl-Dickstein et al.** - Diffusion Models (2015)
- **Jonathan Ho et al.** - DDPM (2020)
- **Robin Rombach et al.** - Stable Diffusion (2022)
- **Aditya Ramesh et al.** - DALL-E (2021)

### æ·±åº¦å¼·åŒ–å­¸ç¿’

- **Volodymyr Mnih et al.** - DQN, A3C (2015-2016)
- **John Schulman et al.** - TRPO, PPO (2015-2017)
- **David Silver et al.** - AlphaGo, AlphaZero (2016-2017)

### è¨ˆç®—æ©Ÿè¦–è¦º

- **Joseph Redmon et al.** - YOLO (2016)
- **Kaiming He et al.** - ResNet, Mask R-CNN (2015-2017)
- **Alexey Dosovitskiy et al.** - Vision Transformer (2020)

### å¯è§£é‡‹ AI

- **Marco Tulio Ribeiro et al.** - LIME (2016)
- **Scott Lundberg & Su-In Lee** - SHAP (2017)

---

## ğŸ“ˆ å¯¦ç¾å„ªå…ˆç´š

### High Priority (ç¬¬ä¸€éšæ®µ)

1. Transformer æ¶æ§‹å®Œæ•´å¯¦ç¾
2. BERT å’Œ GPT åŸºç¤æ¨¡å‹
3. åŸºæœ¬ Diffusion Models
4. DQN å’Œ PPO
5. YOLO ç›®æ¨™æª¢æ¸¬

### Medium Priority (ç¬¬äºŒéšæ®µ)

6. å®Œæ•´çš„ GAN å®¶æ—
7. å…ƒå­¸ç¿’ç®—æ³•ï¼ˆMAMLï¼‰
8. è‡ªç›£ç£å­¸ç¿’ï¼ˆSimCLR, MoCoï¼‰
9. å¯è§£é‡‹ AIï¼ˆLIME, SHAPï¼‰
10. Vision Transformer

### Low Priority (ç¬¬ä¸‰éšæ®µ)

11. ç¥ç¶“æ¶æ§‹æœç´¢
12. è¯é‚¦å­¸ç¿’
13. ä¸–ç•Œæ¨¡å‹
14. é€²éš Transformer è®Šé«”

---

## ğŸ”— æ–°å¢æª”æ¡ˆçµæ§‹

```python
aima-python/
â”œâ”€â”€ deep_learning.py          # æ·±åº¦å­¸ç¿’åŸºç¤
â”œâ”€â”€ attention.py              # æ³¨æ„åŠ›æ©Ÿåˆ¶
â”œâ”€â”€ transformers.py           # Transformer æ¶æ§‹
â”œâ”€â”€ language_models.py        # å¤§å‹èªè¨€æ¨¡å‹
â”œâ”€â”€ generative.py             # ç”Ÿæˆæ¨¡å‹ï¼ˆVAE, GANï¼‰
â”œâ”€â”€ diffusion.py              # æ“´æ•£æ¨¡å‹
â”œâ”€â”€ multimodal.py             # å¤šæ¨¡æ…‹æ¨¡å‹
â”œâ”€â”€ deep_rl.py                # æ·±åº¦å¼·åŒ–å­¸ç¿’
â”œâ”€â”€ games_rl.py               # éŠæˆ² AIï¼ˆAlphaZero ç­‰ï¼‰
â”œâ”€â”€ ssl.py                    # è‡ªç›£ç£å­¸ç¿’
â”œâ”€â”€ meta_learning.py          # å…ƒå­¸ç¿’
â”œâ”€â”€ nas.py                    # ç¥ç¶“æ¶æ§‹æœç´¢
â”œâ”€â”€ explainable_ai.py         # å¯è§£é‡‹ AI
â”œâ”€â”€ federated.py              # è¯é‚¦å­¸ç¿’
â”œâ”€â”€ privacy.py                # éš±ç§ä¿è­·
â”œâ”€â”€ optimizers.py             # å„ªåŒ–å™¨
â”œâ”€â”€ embeddings.py             # è©åµŒå…¥
â”œâ”€â”€ tokenizers.py             # åˆ†è©å™¨
â”œâ”€â”€ object_detection.py       # ç›®æ¨™æª¢æ¸¬
â”œâ”€â”€ segmentation.py           # åœ–åƒåˆ†å‰²
â”œâ”€â”€ vision_models.py          # è¦–è¦ºæ¨¡å‹
â”œâ”€â”€ sequence_models.py        # åºåˆ—æ¨¡å‹
â”œâ”€â”€ datasets.py               # æ•¸æ“šé›†å·¥å…·
â””â”€â”€ visualizers.py            # å¯è¦–åŒ–å·¥å…·
```

---

## ğŸ“ å¯¦ç¾å»ºè­°

### ä»£ç¢¼é¢¨æ ¼

- éµå¾ªç¾æœ‰çš„ Python 3.7+ é¢¨æ ¼
- ä½¿ç”¨ Type Hints
- å®Œæ•´çš„ Docstrings
- å–®å…ƒæ¸¬è©¦è¦†è“‹
- Jupyter Notebook ç¤ºä¾‹

### ä¾è³´ç®¡ç†

```python
# æ–°å¢ä¾è³´
torch>=2.0.0
transformers>=4.30.0
diffusers>=0.21.0
einops>=0.6.0
timm>=0.9.0
```

### æ¸¬è©¦ç­–ç•¥

- å–®å…ƒæ¸¬è©¦ï¼šæ¯å€‹ç®—æ³•ç¨ç«‹æ¸¬è©¦
- é›†æˆæ¸¬è©¦ï¼šå®Œæ•´pipelineæ¸¬è©¦
- æ•ˆèƒ½æ¸¬è©¦ï¼šèˆ‡baselineæ¯”è¼ƒ
- å¯è¦–åŒ–æ¸¬è©¦ï¼šè¼¸å‡ºè³ªé‡æª¢æŸ¥

---

## ğŸ¯ æ•™è‚²åƒ¹å€¼

é€™äº›æ–°ç®—æ³•åæ˜ äº†ï¼š

1. **æ·±åº¦å­¸ç¿’é©å‘½**ï¼ˆ2012-2020ï¼‰
2. **Transformer æ™‚ä»£**ï¼ˆ2017-ç¾åœ¨ï¼‰
3. **ç”Ÿæˆå¼ AI çˆ†ç™¼**ï¼ˆ2020-ç¾åœ¨ï¼‰
4. **è² è²¬ä»» AI**ï¼ˆå¯è§£é‡‹æ€§ã€éš±ç§ï¼‰
5. **æ•ˆç‡èˆ‡å¯æ“´å±•æ€§**ï¼ˆNASã€è¯é‚¦å­¸ç¿’ï¼‰

---

## ğŸŒ èˆ‡å°é¢äººç‰©çš„è¯ç¹«

é€™äº›ç¾ä»£ç®—æ³•å»¶çºŒäº†å°é¢äººç‰©çš„éºç”¢ï¼š

- **è‰¾é”Â·æ´›èŠ™èŠæ–¯** â†’ GPT ç­‰å¯ä»¥"å‰µä½œ"çš„ AI
- **åœ–éˆ** â†’ Transformer çš„æ³¨æ„åŠ›æ©Ÿåˆ¶
- **è²è‘‰æ–¯** â†’ ç¾ä»£æ¦‚ç‡ç”Ÿæˆæ¨¡å‹
- **è¾›é “** â†’ æ·±åº¦å­¸ç¿’çš„å¯¦ç¾è€…

---

## ğŸ“š åƒè€ƒè³‡æº

### é‡è¦è«–æ–‡

- "Attention Is All You Need" (Vaswani et al., 2017)
- "BERT: Pre-training of Deep Bidirectional Transformers" (Devlin et al., 2018)
- "Language Models are Few-Shot Learners" (Brown et al., 2020)
- "Denoising Diffusion Probabilistic Models" (Ho et al., 2020)

### åœ¨ç·šè³‡æº

- [Papers With Code](https://paperswithcode.com/)
- [Hugging Face](https://huggingface.co/)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)

---

**æ³¨æ„**: ğŸŒŸ æ¨™è¨˜çš„ç®—æ³•æ˜¯æ ¸å¿ƒç®—æ³•ï¼Œæ‡‰å„ªå…ˆå¯¦ç¾å’Œæ¸¬è©¦ã€‚

<!---æ–°å¢æª”æ¡ˆå¼•ç”¨é€£çµ-->
[dl]:../master/deep_learning.py
[attn]:../master/attention.py
[trans]:../master/transformers.py
[lm]:../master/language_models.py
[gen]:../master/generative.py
[diff]:../master/diffusion.py
[mm]:../master/multimodal.py
[drl]:../master/deep_rl.py
[grl]:../master/games_rl.py
[ssl]:../master/ssl.py
[meta]:../master/meta_learning.py
[nas]:../master/nas.py
[xai]:../master/explainable_ai.py
[fed]:../master/federated.py
[priv]:../master/privacy.py
[opt]:../master/optimizers.py
[emb]:../master/embeddings.py
[tok]:../master/tokenizers.py
[od]:../master/object_detection.py
[seg]:../master/segmentation.py
[vis]:../master/vision_models.py
[seq]:../master/sequence_models.py
[data]:../master/datasets.py
[viz]:../master/visualizers.py
[utils]:../master/utils.py

